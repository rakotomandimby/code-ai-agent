# Make the LLM API keys to be obtained fron the clients. 

Currently, I must set the LLM API keys as environment variables:

- `OPENAI_API_KEY` - OpenAI API authentication
- `GOOGLEAI_API_KEY` - Google AI API authentication  
- `ANTHROPIC_API_KEY` - Anthropic API authentication

I dont like that. I want the clients to provide the API keys in the requests body.

I  want to handle the API key as a special piece of data that is held in memory at the router level.

Here is the proposed flow:

1.  **Modify `createAgentRouter`**: Introduce a variable within the router's scope (e.g., `let apiKey: string | null = null;`) to store the key in memory.
2.  **Capture the Key**: When a POST request arrives, check if it contains an `api_key` property. If it does, store its value in the `apiKey` variable and do not create a `Chunk` for it.
3.  **Pass the Key to the HTTP Client**: Inside the `setTimeout` block, when you create the `aiHttpClient` instance, pass the stored `apiKey` to it through a new method (e.g., `aiHttpClient.setApiKey(apiKey)`).
4.  **Modify `AIHttpClient`**:
    *   Add a new `setApiKey(key: string)` method.
    *   Modify the logic so that if an API key is provided via this method, it is used for authentication. If not, it fails with a clear error message and the expected response structure.

This approach keeps the API key in memory only for the duration of the request cycle. It respects the core architecture for handling conversational state while treating sensitive authentication data with the appropriate care.

Then tell me the structure of the body of the POST request that the clients must send to the agents.

Tell me the  full new content of the files I need to modify to implement this change.


# ANT Implement Client-Provided API Keys Instead of Environment Variables

I implement a solution to accept API keys from client requests instead of requiring them as environment variables. The API keys are stored in memory at the router level and passed to the HTTP client for authentication. This approach maintains security by keeping keys in memory only during request processing while following the existing architecture patterns.

## Files to Modify

### 1. `lib/src/agent-router.ts`

```typescript
import express from 'express';
import { Request, Response, Router } from 'express';
import { Chunk, BaseRepository } from '@code-ai-agent/lib';
import { AIHttpClient } from './ai-http-client';

export function createAgentRouter(
  repository: BaseRepository,
  agentName: string,
  aiHttpClientConstructor: { new (): AIHttpClient },
  agentBodyConstructor: { new (): any }
): Router {
  const router: Router = express.Router();
  let counter: number = 1000;
  let apiKey: string | null = null; // Store API key in router scope

  router.get('/', (req: Request, res: Response) => {
    res.send('Hello from shared router!');
  });

  router.get(`/${agentName}/clear`, async (req: Request, res: Response) => {
    await repository.clear();
    apiKey = null; // Clear API key when clearing conversation
    res.send({});
  });

  router.post(`/${agentName}`, async (req: Request, res: Response) => {
    await repository.init();
    let JSONBody = req.body;

    // Capture API key if provided
    if (JSONBody.api_key) {
      apiKey = JSONBody.api_key;
      // Don't save api_key to database, just keep in memory
      delete JSONBody.api_key;
    }

    const handleProperty = async (propertyName: string) => {
      counter++;
      if (JSONBody[propertyName]) {
        let chunk = new Chunk(propertyName, counter, '', JSONBody[propertyName]);
        await repository.save(chunk);
      }
    };

    await Promise.all([
      handleProperty('system_instruction'),
      handleProperty('model_to_use'),
      handleProperty('temperature'),
      handleProperty('top_p'),
    ]);

    if (JSONBody.role && JSONBody.content) {
      counter++;
      let chunk = new Chunk('message', counter, JSONBody.role, JSONBody.content);
      await repository.save(chunk);
    }

    if (Object.keys(JSONBody).length === 0) {
      setTimeout(async () => {
        try {
          const agentBody = new agentBodyConstructor();

          const modelToUse = await repository.getModelToUse();
          agentBody.setModelToUse(modelToUse);

          const systemInstruction = await repository.getSystemInstruction();
          agentBody.setSystemInstruction(systemInstruction);

          const multiTurnText = await repository.getMultiTurnChat();
          agentBody.setMultiTurnChat(multiTurnText);

          const temperature = await repository.getTemperature();
          agentBody.setTemperature(parseFloat(temperature));

          const topP = await repository.getTopP();
          agentBody.setTopP(parseFloat(topP));

          console.log(`>>>>> ${agentName} ${modelToUse} has been queried`);

          // --- Start timing here ---
          const startTime = Date.now();

          const aiHttpClient = new aiHttpClientConstructor();
          
          // Set the API key if available
          if (apiKey) {
            aiHttpClient.setApiKey(apiKey);
          }
          
          aiHttpClient.setBody(agentBody.getBody());
          aiHttpClient.setModel(modelToUse);

          const response = await aiHttpClient.post();

          // --- End timing here ---
          const endTime = Date.now();
          const durationMs = endTime - startTime;
          // convert to seconds
          const durationSec = (durationMs / 1000).toFixed(2);
          res.send(response);

          if (modelToUse === 'disabled') {
            console.log(`<<<<< ${agentName} ${modelToUse} - Response for disabled model sent (took ${durationSec} s)`);
          } else {
            console.log(`<<<<< ${agentName} ${modelToUse} has responded (took ${durationSec} s)`);
          }

          await repository.clear();
          apiKey = null; // Clear API key after request completion
        } catch (err) {
          res.status(500).send(err);
          await repository.clear();
          apiKey = null; // Clear API key on error
        }
      }, 1000);
    } else {
      res.send({});
    }
  });

  return router;
}
```

### 2. `lib/src/ai-http-client.ts`

```typescript
import axios, { AxiosError } from 'axios';
import getDisabledModelResponse from './get-disabled-model-response';
import getGoogleAIErrorResponse from './get-googleai-error-response';
import getOpenAIErrorResponse from './get-openai-error-response';
import getAnthropicErrorResponse from './get-anthropic-error-response';

export class AIHttpClient {
  protected provider: string;
  protected url: string;
  protected debugURL: string;
  protected body: object;
  protected model: string | undefined;
  protected token: string;
  protected tokenHeaderName: string;
  protected tokenHeaderValue: string;
  protected apiVersionHeaderName: string;
  protected apiVersionHeaderValue: string;
  protected apiKeyProvided: boolean;

  constructor(provider: string) {
    this.provider = provider;
    this.body = {};
    this.url = '';
    this.token = '';
    this.tokenHeaderName = '';
    this.tokenHeaderValue = '';
    this.apiVersionHeaderName = '';
    this.apiVersionHeaderValue = '';
    this.model = undefined;
    this.debugURL = '';
    this.apiKeyProvided = false;
  }

  setBody(body: object) {
    this.body = body;
  }

  setModel(model: string) {
    this.model = model;
  }

  setApiKey(apiKey: string) {
    this.token = apiKey;
    this.apiKeyProvided = true;
    // Update the token header value based on provider
    if (this.provider === 'openai') {
      this.tokenHeaderValue = `Bearer ${this.token}`;
    } else {
      this.tokenHeaderValue = this.token;
    }
  }

  async post(): Promise<Object> {
    if (this.model === 'disabled') {
      return getDisabledModelResponse(this.provider);
    }

    // Check if API key was provided
    if (!this.apiKeyProvided || !this.token) {
      const errorMessage = `API key not provided for ${this.provider}. Please include 'api_key' in your request body.`;
      console.error(`<<<<< ${this.provider} Error: ${errorMessage}`);
      
      // Return provider-specific error response
      if (this.provider === 'openai') {
        return getOpenAIErrorResponse(errorMessage);
      } else if (this.provider === 'googleai') {
        return getGoogleAIErrorResponse(errorMessage);
      } else if (this.provider === 'anthropic') {
        return getAnthropicErrorResponse(errorMessage);
      }
      
      throw new Error(errorMessage);
    }

    try {
      axios.defaults.headers.common[this.tokenHeaderName] = this.tokenHeaderValue;
      if (this.provider === 'anthropic') {
        axios.defaults.headers.common[this.apiVersionHeaderName] = this.apiVersionHeaderValue;
      }
      if (this.provider === 'googleai' && this.model) {
        this.url = `https://generativelanguage.googleapis.com/v1beta/models/${this.model}:generateContent`;
        this.debugURL = `https://eo95iwu8zyev9gb.m.pipedream.net/v1beta/models/${this.model}:generateContent`;
      }

      const response = await axios.post(this.url, this.body);
      // axios.post(this.debugURL, this.body);
      return response.data;
    } catch (error) {
      if (axios.isAxiosError(error)) {
        const axiosError = error as AxiosError<any>;

        // Handle OpenAI specific errors
        if (
          this.provider === 'openai' &&
          axiosError.response &&
          axiosError.response.data &&
          axiosError.response.data.error &&
          axiosError.response.data.error.message
        ) {
          const errorMessage = axiosError.response.data.error.message;
          console.error(`<<<<< ${this.provider} API Error: ${axiosError.response.status} - ${errorMessage}`);
          return getOpenAIErrorResponse(errorMessage);
        }
        // Handle GoogleAI specific errors
        else if (
          this.provider === 'googleai' &&
          axiosError.response &&
          axiosError.response.data &&
          axiosError.response.data.error &&
          axiosError.response.data.error.message
        ) {
          const errorMessage = axiosError.response.data.error.message;
          console.error(`<<<<< ${this.provider} API Error: ${axiosError.response.status} - ${errorMessage}`);
          return getGoogleAIErrorResponse(errorMessage);
        }
        // Handle Anthropic specific errors
        else if (
          this.provider === 'anthropic' &&
          axiosError.response &&
          axiosError.response.data &&
          axiosError.response.data.error &&
          axiosError.response.data.error.message
        ) {
          const errorMessage = axiosError.response.data.error.message;
          console.error(`<<<<< ${this.provider} API Error: ${axiosError.response.status} - ${errorMessage}`);
          return getAnthropicErrorResponse(errorMessage);
        } else if (axiosError.response) {
          console.error(`<<<<< ${this.provider} HTTP Error: ${axiosError.response.status} ${axiosError.response.statusText}`);
          console.error(`<<<<< ${this.provider} Response body: ${JSON.stringify(axiosError.response.data)}`);
        } else if (axiosError.request) {
          console.error(`----- No response received from the ${this.provider} server`);
        } else {
          console.error(`----- Error setting up the request to ${this.provider}:`, axiosError.message);
        }
      } else {
        console.error(`!!!!! Non-Axios error occurred for ${this.provider}:`, error);
      }
      throw error;
    }
  }

  protected initClient() {
    if (this.provider === 'openai') {
      this.url = 'https://api.openai.com/v1/chat/completions';
      this.debugURL = 'https://eo95iwu8zyev9gb.m.pipedream.net/v1/chat/completions';
      // Don't set token from environment anymore
      this.tokenHeaderName = 'Authorization';
      // tokenHeaderValue will be set when setApiKey is called
    } else if (this.provider === 'googleai') {
      // Don't set token from environment anymore
      this.tokenHeaderName = 'x-goog-api-key';
      // tokenHeaderValue will be set when setApiKey is called
      // The specific model URL is set in the post method for GoogleAI
    } else if (this.provider === 'anthropic') {
      this.url = 'https://api.anthropic.com/v1/messages';
      this.debugURL = 'https://eo95iwu8zyev9gb.m.pipedream.net/v1/messages';
      // Don't set token from environment anymore
      this.tokenHeaderName = 'x-api-key';
      // tokenHeaderValue will be set when setApiKey is called
      this.apiVersionHeaderName = 'anthropic-version';
      this.apiVersionHeaderValue = '2023-06-01';
    }
  }
}
```

## Request Body Structure

Clients must now include the `api_key` field in their POST requests to any agent endpoint. Here's the structure:

### Initial Request (with configuration)
```json
{
  "api_key": "your-api-key-here",
  "system_instruction": "You are a helpful assistant",
  "model_to_use": "gpt-4",
  "temperature": "0.7",
  "top_p": "0.9",
  "role": "user",
  "content": "Hello, how are you?"
}
```

### Subsequent Messages (in the same conversation)
```json
{
  "api_key": "your-api-key-here",
  "role": "user",
  "content": "What's the weather like?"
}
```

### Trigger Processing (empty body)
```json
{}
```

## Key Changes Summary

1. **Router Level**: Added `apiKey` variable in router scope to store the API key in memory during request processing
2. **API Key Extraction**: The router now extracts `api_key` from request body and stores it without saving to database
3. **API Key Passing**: The router passes the stored API key to the HTTP client via the new `setApiKey()` method
4. **HTTP Client Validation**: The HTTP client now validates that an API key was provided and returns appropriate error responses if missing
5. **Environment Variables Removed**: The HTTP client no longer reads API keys from environment variables
6. **Memory Management**: API keys are cleared after request completion or on errors to prevent memory leaks

The solution maintains the existing architecture while treating API keys as sensitive, ephemeral data that exists only in memory during request processing.

Anthropic claude-opus-4-1-20250805 (17k in, 3k out)


